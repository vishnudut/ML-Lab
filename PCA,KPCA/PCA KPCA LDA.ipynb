{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab-Assignment 9\n",
    "\n",
    "- V.VISHNU DUT\n",
    "- 16BCE1103\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets:<br>\n",
    "\n",
    "Wine dataset and Wheat seed dataset<br>\n",
    "\n",
    "Wine - non linear<br>\n",
    "WheatSeed - Linear<br>\n",
    "\n",
    "We first classify them and get their results and then apply dimensionality reduction and then apply classification algorithm on them, and then get their results.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wheat seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_Names=[\"area\", \"perimeter\", \"compactness\", \"lengthOfKernel\", \"widthOfKernel\", \"asymmetryCoefficient\", \"lengthOfKernelGroove\", \"TypeOfWheatSeed\"]\n",
    "data = pd.read_csv(\"seeds_dataset.csv\",names=col_Names, header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>perimeter</th>\n",
       "      <th>compactness</th>\n",
       "      <th>lengthOfKernel</th>\n",
       "      <th>widthOfKernel</th>\n",
       "      <th>asymmetryCoefficient</th>\n",
       "      <th>lengthOfKernelGroove</th>\n",
       "      <th>TypeOfWheatSeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.26</td>\n",
       "      <td>14.84</td>\n",
       "      <td>0.8710</td>\n",
       "      <td>5.763</td>\n",
       "      <td>3.312</td>\n",
       "      <td>2.221</td>\n",
       "      <td>5.220</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.88</td>\n",
       "      <td>14.57</td>\n",
       "      <td>0.8811</td>\n",
       "      <td>5.554</td>\n",
       "      <td>3.333</td>\n",
       "      <td>1.018</td>\n",
       "      <td>4.956</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.29</td>\n",
       "      <td>14.09</td>\n",
       "      <td>0.9050</td>\n",
       "      <td>5.291</td>\n",
       "      <td>3.337</td>\n",
       "      <td>2.699</td>\n",
       "      <td>4.825</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.84</td>\n",
       "      <td>13.94</td>\n",
       "      <td>0.8955</td>\n",
       "      <td>5.324</td>\n",
       "      <td>3.379</td>\n",
       "      <td>2.259</td>\n",
       "      <td>4.805</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.14</td>\n",
       "      <td>14.99</td>\n",
       "      <td>0.9034</td>\n",
       "      <td>5.658</td>\n",
       "      <td>3.562</td>\n",
       "      <td>1.355</td>\n",
       "      <td>5.175</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    area  perimeter  compactness  lengthOfKernel  widthOfKernel  \\\n",
       "0  15.26      14.84       0.8710           5.763          3.312   \n",
       "1  14.88      14.57       0.8811           5.554          3.333   \n",
       "2  14.29      14.09       0.9050           5.291          3.337   \n",
       "3  13.84      13.94       0.8955           5.324          3.379   \n",
       "4  16.14      14.99       0.9034           5.658          3.562   \n",
       "\n",
       "   asymmetryCoefficient  lengthOfKernelGroove  TypeOfWheatSeed  \n",
       "0                 2.221                 5.220                1  \n",
       "1                 1.018                 4.956                1  \n",
       "2                 2.699                 4.825                1  \n",
       "3                 2.259                 4.805                1  \n",
       "4                 1.355                 5.175                1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "area                    False\n",
       "perimeter               False\n",
       "compactness             False\n",
       "lengthOfKernel          False\n",
       "widthOfKernel           False\n",
       "asymmetryCoefficient    False\n",
       "lengthOfKernelGroove    False\n",
       "TypeOfWheatSeed         False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[[\"area\",\"perimeter\",\"compactness\",\"lengthOfKernel\",\"widthOfKernel\",\"asymmetryCoefficient\",\"lengthOfKernelGroove\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = data[[\"TypeOfWheatSeed\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split  \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression  \n",
    "regressor = LinearRegression()  \n",
    "regressor.fit(X_train, y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[49.32930855]\n"
     ]
    }
   ],
   "source": [
    "print(regressor.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.29678468  -2.87904628 -29.27178945  -2.44906132   0.45732162\n",
      "    0.12881309   2.34067356]]\n"
     ]
    }
   ],
   "source": [
    "print(regressor.coef_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.26781816440579814\n",
      "Mean Squared Error: 0.10513096161958353\n",
      "Root Mean Squared Error: 0.3242390501151635\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics  \n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))  \n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))  \n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9285714285714286"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(Y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2 = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9285714285714286"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(Y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionality reduction PCA and Kernel PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.datasets import make_circles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "kpca = KernelPCA(kernel=\"rbf\", gamma=15)\n",
    "X_kpca = kpca.fit_transform(X)\n",
    "\n",
    "pca = PCA(n_components='mle', svd_solver='full')\n",
    "X_pca = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of features: 7\n",
      "Reduced number of features KPCA: 210\n",
      "Reduced number of features PCA: 6\n"
     ]
    }
   ],
   "source": [
    "print('Original number of features:', X.shape[1])\n",
    "print('Reduced number of features KPCA:', X_kpca.shape[1])\n",
    "print('Reduced number of features PCA:', X_pca.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split  \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_kpca, Y, test_size=0.2, random_state=0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2 = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6904761904761905"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(Y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split  \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, Y, test_size=0.2, random_state=0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2 = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9047619047619048"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(Y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LDA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,\n",
       "              solver='svd', store_covariance=False, tol=0.0001)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split  \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2 = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "Y_pred = clf.predict(X_test)\n",
    "accuracy_score(Y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wine dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will be doing Simple Linear Regression from scratch with one attribute and not multiple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed.acidity</th>\n",
       "      <th>volatile.acidity</th>\n",
       "      <th>citric.acid</th>\n",
       "      <th>residual.sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free.sulfur.dioxide</th>\n",
       "      <th>total.sulfur.dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.090</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.58</td>\n",
       "      <td>10.5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.062</td>\n",
       "      <td>39.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.99512</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.76</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.076</td>\n",
       "      <td>29.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.99574</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.75</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.075</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99547</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.71</td>\n",
       "      <td>10.2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.47</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.067</td>\n",
       "      <td>18.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.99549</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.66</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed.acidity  volatile.acidity  citric.acid  residual.sugar  chlorides  \\\n",
       "1594            6.2             0.600         0.08             2.0      0.090   \n",
       "1595            5.9             0.550         0.10             2.2      0.062   \n",
       "1596            6.3             0.510         0.13             2.3      0.076   \n",
       "1597            5.9             0.645         0.12             2.0      0.075   \n",
       "1598            6.0             0.310         0.47             3.6      0.067   \n",
       "\n",
       "      free.sulfur.dioxide  total.sulfur.dioxide  density    pH  sulphates  \\\n",
       "1594                 32.0                  44.0  0.99490  3.45       0.58   \n",
       "1595                 39.0                  51.0  0.99512  3.52       0.76   \n",
       "1596                 29.0                  40.0  0.99574  3.42       0.75   \n",
       "1597                 32.0                  44.0  0.99547  3.57       0.71   \n",
       "1598                 18.0                  42.0  0.99549  3.39       0.66   \n",
       "\n",
       "      alcohol  quality  \n",
       "1594     10.5        5  \n",
       "1595     11.2        6  \n",
       "1596     11.0        6  \n",
       "1597     10.2        5  \n",
       "1598     11.0        6  "
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"wineQualityReds.csv\")\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data set framing\n",
    "X = data[[\"fixed.acidity\",\"volatile.acidity\",\"citric.acid\",\"residual.sugar\",\"chlorides\",\"free.sulfur.dioxide\",\"density\",\"pH\",\"sulphates\",\"alcohol\",\"quality\"\n",
    "]]\n",
    "y = data[\"total.sulfur.dioxide\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor = LinearRegression()  \n",
    "regressor.fit(X_train, y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fixed.acidity</th>\n",
       "      <td>-8.485644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>volatile.acidity</th>\n",
       "      <td>31.097172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>citric.acid</th>\n",
       "      <td>51.330384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>residual.sugar</th>\n",
       "      <td>0.214701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chlorides</th>\n",
       "      <td>-90.204921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>free.sulfur.dioxide</th>\n",
       "      <td>1.923942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>density</th>\n",
       "      <td>3052.535744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pH</th>\n",
       "      <td>-50.852843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sulphates</th>\n",
       "      <td>9.164450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alcohol</th>\n",
       "      <td>-1.556867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quality</th>\n",
       "      <td>-4.113030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Coefficient\n",
       "fixed.acidity          -8.485644\n",
       "volatile.acidity       31.097172\n",
       "citric.acid            51.330384\n",
       "residual.sugar          0.214701\n",
       "chlorides             -90.204921\n",
       "free.sulfur.dioxide     1.923942\n",
       "density              3052.535744\n",
       "pH                    -50.852843\n",
       "sulphates               9.164450\n",
       "alcohol                -1.556867\n",
       "quality                -4.113030"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeff_df = pd.DataFrame(regressor.coef_, X.columns, columns=['Coefficient'])  \n",
    "coeff_df  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>16.0</td>\n",
       "      <td>19.330052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>73.0</td>\n",
       "      <td>75.497612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>38.0</td>\n",
       "      <td>37.493413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>52.0</td>\n",
       "      <td>68.819998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>39.0</td>\n",
       "      <td>33.728249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1246</th>\n",
       "      <td>48.0</td>\n",
       "      <td>54.755397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>12.0</td>\n",
       "      <td>36.596074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1531</th>\n",
       "      <td>28.0</td>\n",
       "      <td>43.944190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>8.0</td>\n",
       "      <td>7.447259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>939</th>\n",
       "      <td>11.0</td>\n",
       "      <td>18.225564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>101.0</td>\n",
       "      <td>54.862939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098</th>\n",
       "      <td>16.0</td>\n",
       "      <td>9.902397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1286</th>\n",
       "      <td>31.0</td>\n",
       "      <td>39.593095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>66.0</td>\n",
       "      <td>63.447549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1555</th>\n",
       "      <td>24.0</td>\n",
       "      <td>36.423453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>38.0</td>\n",
       "      <td>59.418472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>25.0</td>\n",
       "      <td>28.469457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384</th>\n",
       "      <td>84.0</td>\n",
       "      <td>69.800687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306</th>\n",
       "      <td>91.0</td>\n",
       "      <td>61.248755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1325</th>\n",
       "      <td>34.0</td>\n",
       "      <td>48.948733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>68.0</td>\n",
       "      <td>76.863455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1324</th>\n",
       "      <td>34.0</td>\n",
       "      <td>48.948733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>13.0</td>\n",
       "      <td>32.607912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1526</th>\n",
       "      <td>38.0</td>\n",
       "      <td>50.298491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1064</th>\n",
       "      <td>10.0</td>\n",
       "      <td>14.741198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>51.0</td>\n",
       "      <td>88.111080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1513</th>\n",
       "      <td>65.0</td>\n",
       "      <td>45.520873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1561</th>\n",
       "      <td>131.0</td>\n",
       "      <td>87.757572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1461</th>\n",
       "      <td>13.0</td>\n",
       "      <td>34.208826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>54.0</td>\n",
       "      <td>48.038298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1580</th>\n",
       "      <td>26.0</td>\n",
       "      <td>27.050889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015</th>\n",
       "      <td>27.0</td>\n",
       "      <td>39.748566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>42.0</td>\n",
       "      <td>48.410790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1125</th>\n",
       "      <td>27.0</td>\n",
       "      <td>27.092192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435</th>\n",
       "      <td>95.0</td>\n",
       "      <td>132.043973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>48.0</td>\n",
       "      <td>64.339721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1187</th>\n",
       "      <td>39.0</td>\n",
       "      <td>20.459237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1420</th>\n",
       "      <td>19.0</td>\n",
       "      <td>17.486901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>29.0</td>\n",
       "      <td>25.954775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846</th>\n",
       "      <td>31.0</td>\n",
       "      <td>49.634510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815</th>\n",
       "      <td>38.0</td>\n",
       "      <td>43.256737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1147</th>\n",
       "      <td>14.0</td>\n",
       "      <td>17.531492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1587</th>\n",
       "      <td>28.0</td>\n",
       "      <td>47.629091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>15.0</td>\n",
       "      <td>33.701577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1079</th>\n",
       "      <td>278.0</td>\n",
       "      <td>104.478628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1502</th>\n",
       "      <td>60.0</td>\n",
       "      <td>52.652821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1071</th>\n",
       "      <td>92.0</td>\n",
       "      <td>100.662057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1395</th>\n",
       "      <td>12.0</td>\n",
       "      <td>16.653327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>34.0</td>\n",
       "      <td>31.827588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>28.0</td>\n",
       "      <td>3.153583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>9.0</td>\n",
       "      <td>21.442490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>15.0</td>\n",
       "      <td>34.523217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>13.0</td>\n",
       "      <td>39.195501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>59.0</td>\n",
       "      <td>51.141210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>27.0</td>\n",
       "      <td>29.438706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>12.0</td>\n",
       "      <td>22.317761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>28.0</td>\n",
       "      <td>48.328948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>38.0</td>\n",
       "      <td>26.123192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>909</th>\n",
       "      <td>11.0</td>\n",
       "      <td>25.492488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>16.0</td>\n",
       "      <td>11.821643</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Actual   Predicted\n",
       "336     16.0   19.330052\n",
       "82      73.0   75.497612\n",
       "235     38.0   37.493413\n",
       "607     52.0   68.819998\n",
       "66      39.0   33.728249\n",
       "1246    48.0   54.755397\n",
       "48      12.0   36.596074\n",
       "1531    28.0   43.944190\n",
       "1021     8.0    7.447259\n",
       "939     11.0   18.225564\n",
       "166    101.0   54.862939\n",
       "1098    16.0    9.902397\n",
       "1286    31.0   39.593095\n",
       "752     66.0   63.447549\n",
       "1555    24.0   36.423453\n",
       "594     38.0   59.418472\n",
       "701     25.0   28.469457\n",
       "1384    84.0   69.800687\n",
       "1306    91.0   61.248755\n",
       "1325    34.0   48.948733\n",
       "993     68.0   76.863455\n",
       "1324    34.0   48.948733\n",
       "537     13.0   32.607912\n",
       "1526    38.0   50.298491\n",
       "1064    10.0   14.741198\n",
       "1595    51.0   88.111080\n",
       "1513    65.0   45.520873\n",
       "1561   131.0   87.757572\n",
       "1461    13.0   34.208826\n",
       "664     54.0   48.038298\n",
       "...      ...         ...\n",
       "1580    26.0   27.050889\n",
       "1015    27.0   39.748566\n",
       "182     42.0   48.410790\n",
       "1125    27.0   27.092192\n",
       "1435    95.0  132.043973\n",
       "386     48.0   64.339721\n",
       "1187    39.0   20.459237\n",
       "1420    19.0   17.486901\n",
       "297     29.0   25.954775\n",
       "846     31.0   49.634510\n",
       "815     38.0   43.256737\n",
       "1147    14.0   17.531492\n",
       "1587    28.0   47.629091\n",
       "683     15.0   33.701577\n",
       "1079   278.0  104.478628\n",
       "1502    60.0   52.652821\n",
       "1071    92.0  100.662057\n",
       "1395    12.0   16.653327\n",
       "778     34.0   31.827588\n",
       "535     28.0    3.153583\n",
       "688      9.0   21.442490\n",
       "375     15.0   34.523217\n",
       "671     13.0   39.195501\n",
       "320     59.0   51.141210\n",
       "264     27.0   29.438706\n",
       "127     12.0   22.317761\n",
       "981     28.0   48.328948\n",
       "395     38.0   26.123192\n",
       "909     11.0   25.492488\n",
       "128     16.0   11.821643\n",
       "\n",
       "[400 rows x 2 columns]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = regressor.predict(X_test)\n",
    "df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})  \n",
    "df  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 15.893100141029436\n",
      "Mean Squared Error: 560.1825876096477\n",
      "Root Mean Squared Error: 23.668176685364838\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics  \n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))  \n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))  \n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now applying PCA , kernelPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.datasets import make_circles\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "kpca = KernelPCA(kernel=\"rbf\", gamma=15)\n",
    "X_kpca = kpca.fit_transform(X)\n",
    "\n",
    "pca = PCA(n_components='mle', svd_solver='full')\n",
    "X_pca = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of features: 11\n",
      "Reduced number of features KPCA: 1495\n",
      "Reduced number of features PCA: 10\n"
     ]
    }
   ],
   "source": [
    "print('Original number of features:', X.shape[1])\n",
    "print('Reduced number of features KPCA:', X_kpca.shape[1])\n",
    "print('Reduced number of features PCA:', X_pca.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split  \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_kpca, Y, test_size=0.2, random_state=0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor = LinearRegression()  \n",
    "regressor.fit(X_train, y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.593954</td>\n",
       "      <td>-2.411711e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.987312</td>\n",
       "      <td>1.108097e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.591995</td>\n",
       "      <td>-6.412048e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.987312</td>\n",
       "      <td>2.404462e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.230584</td>\n",
       "      <td>-9.299545e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.928453</td>\n",
       "      <td>9.379654e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.804858</td>\n",
       "      <td>2.940471e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.259456</td>\n",
       "      <td>2.170715e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.835267</td>\n",
       "      <td>3.211203e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.928453</td>\n",
       "      <td>1.106855e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.865676</td>\n",
       "      <td>-5.894671e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.561586</td>\n",
       "      <td>-5.589676e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.987312</td>\n",
       "      <td>-9.530945e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.506223</td>\n",
       "      <td>3.958935e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.470360</td>\n",
       "      <td>-7.572021e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.411500</td>\n",
       "      <td>1.820227e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-1.108948</td>\n",
       "      <td>-9.164124e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.804858</td>\n",
       "      <td>1.717670e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.622404</td>\n",
       "      <td>5.360836e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.531178</td>\n",
       "      <td>1.031145e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-1.078539</td>\n",
       "      <td>-1.694743e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.652813</td>\n",
       "      <td>-9.844002e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.470360</td>\n",
       "      <td>-6.030197e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2.023176</td>\n",
       "      <td>-3.280201e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.077002</td>\n",
       "      <td>4.206639e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2.631355</td>\n",
       "      <td>4.629194e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.749495</td>\n",
       "      <td>5.935104e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.287906</td>\n",
       "      <td>1.508516e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2.205630</td>\n",
       "      <td>8.302017e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.075043</td>\n",
       "      <td>3.623595e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>0.137820</td>\n",
       "      <td>1.123962e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>-0.926494</td>\n",
       "      <td>-5.540977e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>-0.561586</td>\n",
       "      <td>-2.645968e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>-1.048130</td>\n",
       "      <td>-5.641118e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>0.229047</td>\n",
       "      <td>-1.187560e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>-0.774449</td>\n",
       "      <td>-8.581390e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>0.685181</td>\n",
       "      <td>-3.724584e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>-0.105452</td>\n",
       "      <td>3.387915e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>0.472318</td>\n",
       "      <td>-3.821925e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>0.928453</td>\n",
       "      <td>-2.112385e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>-0.409542</td>\n",
       "      <td>-4.167023e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>-1.048130</td>\n",
       "      <td>-4.419251e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>-0.652813</td>\n",
       "      <td>-4.811096e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>0.411500</td>\n",
       "      <td>-2.514300e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>-0.835267</td>\n",
       "      <td>7.679669e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>0.381091</td>\n",
       "      <td>5.229362e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>-0.713631</td>\n",
       "      <td>1.276937e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>-0.804858</td>\n",
       "      <td>1.145896e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>1.019680</td>\n",
       "      <td>-5.197279e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>-0.196679</td>\n",
       "      <td>9.231567e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>1.810313</td>\n",
       "      <td>1.801125e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>-0.196679</td>\n",
       "      <td>-1.283923e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>-0.287906</td>\n",
       "      <td>-3.484879e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>-0.987312</td>\n",
       "      <td>-2.590546e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>0.624363</td>\n",
       "      <td>1.304407e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>-0.622404</td>\n",
       "      <td>2.527383e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>-1.200175</td>\n",
       "      <td>-4.329285e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>-0.865676</td>\n",
       "      <td>-1.428596e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>-0.987312</td>\n",
       "      <td>-9.369454e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>-1.139357</td>\n",
       "      <td>-5.321851e+12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>320 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Actual     Predicted\n",
       "0    0.593954 -2.411711e+11\n",
       "1   -0.987312  1.108097e+12\n",
       "2   -0.591995 -6.412048e-01\n",
       "3   -0.987312  2.404462e+11\n",
       "4   -1.230584 -9.299545e-01\n",
       "5    0.928453  9.379654e-01\n",
       "6   -0.804858  2.940471e+11\n",
       "7    0.259456  2.170715e-01\n",
       "8   -0.835267  3.211203e+12\n",
       "9    0.928453  1.106855e+12\n",
       "10  -0.865676 -5.894671e+12\n",
       "11  -0.561586 -5.589676e-01\n",
       "12  -0.987312 -9.530945e-01\n",
       "13   1.506223  3.958935e+12\n",
       "14  -0.470360 -7.572021e+12\n",
       "15   0.411500  1.820227e+12\n",
       "16  -1.108948 -9.164124e-01\n",
       "17  -0.804858  1.717670e+12\n",
       "18  -0.622404  5.360836e+12\n",
       "19  -0.531178  1.031145e+13\n",
       "20  -1.078539 -1.694743e+12\n",
       "21  -0.652813 -9.844002e+11\n",
       "22  -0.470360 -6.030197e-01\n",
       "23   2.023176 -3.280201e+12\n",
       "24   0.077002  4.206639e+12\n",
       "25   2.631355  4.629194e+11\n",
       "26   1.749495  5.935104e+12\n",
       "27  -0.287906  1.508516e+12\n",
       "28   2.205630  8.302017e+12\n",
       "29  -0.075043  3.623595e+12\n",
       "..        ...           ...\n",
       "290  0.137820  1.123962e-01\n",
       "291 -0.926494 -5.540977e+10\n",
       "292 -0.561586 -2.645968e+01\n",
       "293 -1.048130 -5.641118e+12\n",
       "294  0.229047 -1.187560e+13\n",
       "295 -0.774449 -8.581390e-01\n",
       "296  0.685181 -3.724584e+11\n",
       "297 -0.105452  3.387915e+12\n",
       "298  0.472318 -3.821925e+12\n",
       "299  0.928453 -2.112385e+11\n",
       "300 -0.409542 -4.167023e-01\n",
       "301 -1.048130 -4.419251e+12\n",
       "302 -0.652813 -4.811096e-01\n",
       "303  0.411500 -2.514300e+12\n",
       "304 -0.835267  7.679669e+11\n",
       "305  0.381091  5.229362e+12\n",
       "306 -0.713631  1.276937e+12\n",
       "307 -0.804858  1.145896e+12\n",
       "308  1.019680 -5.197279e+12\n",
       "309 -0.196679  9.231567e-04\n",
       "310  1.810313  1.801125e+00\n",
       "311 -0.196679 -1.283923e+03\n",
       "312 -0.287906 -3.484879e-01\n",
       "313 -0.987312 -2.590546e+12\n",
       "314  0.624363  1.304407e+13\n",
       "315 -0.622404  2.527383e+11\n",
       "316 -1.200175 -4.329285e+12\n",
       "317 -0.865676 -1.428596e+12\n",
       "318 -0.987312 -9.369454e+11\n",
       "319 -1.139357 -5.321851e+12\n",
       "\n",
       "[320 rows x 2 columns]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = regressor.predict(X_test)\n",
    "df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})  \n",
    "df  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 2584015151647.59\n",
      "Mean Squared Error: 1.4246020099333066e+25\n",
      "Root Mean Squared Error: 3774390030101.959\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics  \n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))  \n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))  \n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split  \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, Y, test_size=0.2, random_state=0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor = LinearRegression()  \n",
    "regressor.fit(X_train, y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.593954</td>\n",
       "      <td>0.290676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.987312</td>\n",
       "      <td>-0.650391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.591995</td>\n",
       "      <td>-0.571807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.987312</td>\n",
       "      <td>-0.571446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.230584</td>\n",
       "      <td>-0.944468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.928453</td>\n",
       "      <td>-0.203910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.804858</td>\n",
       "      <td>-0.303015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.259456</td>\n",
       "      <td>1.036284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.835267</td>\n",
       "      <td>-0.463531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.928453</td>\n",
       "      <td>0.404223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.865676</td>\n",
       "      <td>-0.313713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.561586</td>\n",
       "      <td>-0.498554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.987312</td>\n",
       "      <td>-0.804470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.506223</td>\n",
       "      <td>1.476519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.470360</td>\n",
       "      <td>0.330161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.411500</td>\n",
       "      <td>1.191559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-1.108948</td>\n",
       "      <td>-1.071960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.804858</td>\n",
       "      <td>-0.385060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.622404</td>\n",
       "      <td>-0.495913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.531178</td>\n",
       "      <td>-0.379800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-1.078539</td>\n",
       "      <td>-1.039068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.652813</td>\n",
       "      <td>-0.498470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.470360</td>\n",
       "      <td>-0.625588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2.023176</td>\n",
       "      <td>0.321109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.077002</td>\n",
       "      <td>0.165872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2.631355</td>\n",
       "      <td>1.221947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.749495</td>\n",
       "      <td>-0.241538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.287906</td>\n",
       "      <td>0.122317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2.205630</td>\n",
       "      <td>1.135510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.075043</td>\n",
       "      <td>-0.764958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>0.137820</td>\n",
       "      <td>0.444521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>-0.926494</td>\n",
       "      <td>-0.899741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>-0.561586</td>\n",
       "      <td>-1.463672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>-1.048130</td>\n",
       "      <td>-0.983332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>0.229047</td>\n",
       "      <td>0.097240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>-0.774449</td>\n",
       "      <td>-0.230139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>0.685181</td>\n",
       "      <td>0.303135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>-0.105452</td>\n",
       "      <td>0.017481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>0.472318</td>\n",
       "      <td>-0.191399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>0.928453</td>\n",
       "      <td>0.172745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>-0.409542</td>\n",
       "      <td>-0.506155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>-1.048130</td>\n",
       "      <td>-0.903656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>-0.652813</td>\n",
       "      <td>-0.227237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>0.411500</td>\n",
       "      <td>0.783856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>-0.835267</td>\n",
       "      <td>-0.586179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>0.381091</td>\n",
       "      <td>1.325862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>-0.713631</td>\n",
       "      <td>-0.579530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>-0.804858</td>\n",
       "      <td>-0.482637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>1.019680</td>\n",
       "      <td>0.441848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>-0.196679</td>\n",
       "      <td>0.117203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>1.810313</td>\n",
       "      <td>1.754815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>-0.196679</td>\n",
       "      <td>0.733378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>-0.287906</td>\n",
       "      <td>-0.753661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>-0.987312</td>\n",
       "      <td>-0.856852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>0.624363</td>\n",
       "      <td>0.842676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>-0.622404</td>\n",
       "      <td>-0.788178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>-1.200175</td>\n",
       "      <td>-0.834473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>-0.865676</td>\n",
       "      <td>-0.370189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>-0.987312</td>\n",
       "      <td>-0.765268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>-1.139357</td>\n",
       "      <td>-1.003652</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>320 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Actual  Predicted\n",
       "0    0.593954   0.290676\n",
       "1   -0.987312  -0.650391\n",
       "2   -0.591995  -0.571807\n",
       "3   -0.987312  -0.571446\n",
       "4   -1.230584  -0.944468\n",
       "5    0.928453  -0.203910\n",
       "6   -0.804858  -0.303015\n",
       "7    0.259456   1.036284\n",
       "8   -0.835267  -0.463531\n",
       "9    0.928453   0.404223\n",
       "10  -0.865676  -0.313713\n",
       "11  -0.561586  -0.498554\n",
       "12  -0.987312  -0.804470\n",
       "13   1.506223   1.476519\n",
       "14  -0.470360   0.330161\n",
       "15   0.411500   1.191559\n",
       "16  -1.108948  -1.071960\n",
       "17  -0.804858  -0.385060\n",
       "18  -0.622404  -0.495913\n",
       "19  -0.531178  -0.379800\n",
       "20  -1.078539  -1.039068\n",
       "21  -0.652813  -0.498470\n",
       "22  -0.470360  -0.625588\n",
       "23   2.023176   0.321109\n",
       "24   0.077002   0.165872\n",
       "25   2.631355   1.221947\n",
       "26   1.749495  -0.241538\n",
       "27  -0.287906   0.122317\n",
       "28   2.205630   1.135510\n",
       "29  -0.075043  -0.764958\n",
       "..        ...        ...\n",
       "290  0.137820   0.444521\n",
       "291 -0.926494  -0.899741\n",
       "292 -0.561586  -1.463672\n",
       "293 -1.048130  -0.983332\n",
       "294  0.229047   0.097240\n",
       "295 -0.774449  -0.230139\n",
       "296  0.685181   0.303135\n",
       "297 -0.105452   0.017481\n",
       "298  0.472318  -0.191399\n",
       "299  0.928453   0.172745\n",
       "300 -0.409542  -0.506155\n",
       "301 -1.048130  -0.903656\n",
       "302 -0.652813  -0.227237\n",
       "303  0.411500   0.783856\n",
       "304 -0.835267  -0.586179\n",
       "305  0.381091   1.325862\n",
       "306 -0.713631  -0.579530\n",
       "307 -0.804858  -0.482637\n",
       "308  1.019680   0.441848\n",
       "309 -0.196679   0.117203\n",
       "310  1.810313   1.754815\n",
       "311 -0.196679   0.733378\n",
       "312 -0.287906  -0.753661\n",
       "313 -0.987312  -0.856852\n",
       "314  0.624363   0.842676\n",
       "315 -0.622404  -0.788178\n",
       "316 -1.200175  -0.834473\n",
       "317 -0.865676  -0.370189\n",
       "318 -0.987312  -0.765268\n",
       "319 -1.139357  -1.003652\n",
       "\n",
       "[320 rows x 2 columns]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = regressor.predict(X_test)\n",
    "df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})  \n",
    "df  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.4408379007098189\n",
      "Mean Squared Error: 0.36037896897724037\n",
      "Root Mean Squared Error: 0.6003157244127796\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics  \n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))  \n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))  \n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[[\"fixed.acidity\",\"volatile.acidity\",\"citric.acid\",\"residual.sugar\",\"chlorides\",\"free.sulfur.dioxide\",\"density\",\"pH\",\"sulphates\",\"alcohol\",\"quality\"\n",
    "]].values\n",
    "y = data[[\"quality\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,\n",
       "              solver='svd', store_covariance=False, tol=0.0001)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LDA()\n",
    "clf.fit(X, y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split  \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, Y, test_size=0.2, random_state=0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor = LinearRegression()  \n",
    "regressor.fit(X_train, y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.593954</td>\n",
       "      <td>0.290676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.987312</td>\n",
       "      <td>-0.650391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.591995</td>\n",
       "      <td>-0.571807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.987312</td>\n",
       "      <td>-0.571446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.230584</td>\n",
       "      <td>-0.944468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.928453</td>\n",
       "      <td>-0.203910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.804858</td>\n",
       "      <td>-0.303015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.259456</td>\n",
       "      <td>1.036284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.835267</td>\n",
       "      <td>-0.463531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.928453</td>\n",
       "      <td>0.404223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.865676</td>\n",
       "      <td>-0.313713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.561586</td>\n",
       "      <td>-0.498554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.987312</td>\n",
       "      <td>-0.804470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.506223</td>\n",
       "      <td>1.476519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.470360</td>\n",
       "      <td>0.330161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.411500</td>\n",
       "      <td>1.191559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-1.108948</td>\n",
       "      <td>-1.071960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.804858</td>\n",
       "      <td>-0.385060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.622404</td>\n",
       "      <td>-0.495913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.531178</td>\n",
       "      <td>-0.379800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-1.078539</td>\n",
       "      <td>-1.039068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.652813</td>\n",
       "      <td>-0.498470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.470360</td>\n",
       "      <td>-0.625588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2.023176</td>\n",
       "      <td>0.321109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.077002</td>\n",
       "      <td>0.165872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2.631355</td>\n",
       "      <td>1.221947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.749495</td>\n",
       "      <td>-0.241538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.287906</td>\n",
       "      <td>0.122317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2.205630</td>\n",
       "      <td>1.135510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.075043</td>\n",
       "      <td>-0.764958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>0.137820</td>\n",
       "      <td>0.444521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>-0.926494</td>\n",
       "      <td>-0.899741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>-0.561586</td>\n",
       "      <td>-1.463672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>-1.048130</td>\n",
       "      <td>-0.983332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>0.229047</td>\n",
       "      <td>0.097240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>-0.774449</td>\n",
       "      <td>-0.230139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>0.685181</td>\n",
       "      <td>0.303135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>-0.105452</td>\n",
       "      <td>0.017481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>0.472318</td>\n",
       "      <td>-0.191399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>0.928453</td>\n",
       "      <td>0.172745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>-0.409542</td>\n",
       "      <td>-0.506155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>-1.048130</td>\n",
       "      <td>-0.903656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>-0.652813</td>\n",
       "      <td>-0.227237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>0.411500</td>\n",
       "      <td>0.783856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>-0.835267</td>\n",
       "      <td>-0.586179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>0.381091</td>\n",
       "      <td>1.325862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>-0.713631</td>\n",
       "      <td>-0.579530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>-0.804858</td>\n",
       "      <td>-0.482637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>1.019680</td>\n",
       "      <td>0.441848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>-0.196679</td>\n",
       "      <td>0.117203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>1.810313</td>\n",
       "      <td>1.754815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>-0.196679</td>\n",
       "      <td>0.733378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>-0.287906</td>\n",
       "      <td>-0.753661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>-0.987312</td>\n",
       "      <td>-0.856852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>0.624363</td>\n",
       "      <td>0.842676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>-0.622404</td>\n",
       "      <td>-0.788178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>-1.200175</td>\n",
       "      <td>-0.834473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>-0.865676</td>\n",
       "      <td>-0.370189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>-0.987312</td>\n",
       "      <td>-0.765268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>-1.139357</td>\n",
       "      <td>-1.003652</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>320 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Actual  Predicted\n",
       "0    0.593954   0.290676\n",
       "1   -0.987312  -0.650391\n",
       "2   -0.591995  -0.571807\n",
       "3   -0.987312  -0.571446\n",
       "4   -1.230584  -0.944468\n",
       "5    0.928453  -0.203910\n",
       "6   -0.804858  -0.303015\n",
       "7    0.259456   1.036284\n",
       "8   -0.835267  -0.463531\n",
       "9    0.928453   0.404223\n",
       "10  -0.865676  -0.313713\n",
       "11  -0.561586  -0.498554\n",
       "12  -0.987312  -0.804470\n",
       "13   1.506223   1.476519\n",
       "14  -0.470360   0.330161\n",
       "15   0.411500   1.191559\n",
       "16  -1.108948  -1.071960\n",
       "17  -0.804858  -0.385060\n",
       "18  -0.622404  -0.495913\n",
       "19  -0.531178  -0.379800\n",
       "20  -1.078539  -1.039068\n",
       "21  -0.652813  -0.498470\n",
       "22  -0.470360  -0.625588\n",
       "23   2.023176   0.321109\n",
       "24   0.077002   0.165872\n",
       "25   2.631355   1.221947\n",
       "26   1.749495  -0.241538\n",
       "27  -0.287906   0.122317\n",
       "28   2.205630   1.135510\n",
       "29  -0.075043  -0.764958\n",
       "..        ...        ...\n",
       "290  0.137820   0.444521\n",
       "291 -0.926494  -0.899741\n",
       "292 -0.561586  -1.463672\n",
       "293 -1.048130  -0.983332\n",
       "294  0.229047   0.097240\n",
       "295 -0.774449  -0.230139\n",
       "296  0.685181   0.303135\n",
       "297 -0.105452   0.017481\n",
       "298  0.472318  -0.191399\n",
       "299  0.928453   0.172745\n",
       "300 -0.409542  -0.506155\n",
       "301 -1.048130  -0.903656\n",
       "302 -0.652813  -0.227237\n",
       "303  0.411500   0.783856\n",
       "304 -0.835267  -0.586179\n",
       "305  0.381091   1.325862\n",
       "306 -0.713631  -0.579530\n",
       "307 -0.804858  -0.482637\n",
       "308  1.019680   0.441848\n",
       "309 -0.196679   0.117203\n",
       "310  1.810313   1.754815\n",
       "311 -0.196679   0.733378\n",
       "312 -0.287906  -0.753661\n",
       "313 -0.987312  -0.856852\n",
       "314  0.624363   0.842676\n",
       "315 -0.622404  -0.788178\n",
       "316 -1.200175  -0.834473\n",
       "317 -0.865676  -0.370189\n",
       "318 -0.987312  -0.765268\n",
       "319 -1.139357  -1.003652\n",
       "\n",
       "[320 rows x 2 columns]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = regressor.predict(X_test)\n",
    "df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})  \n",
    "df  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.4408379007098189\n",
      "Mean Squared Error: 0.36037896897724037\n",
      "Root Mean Squared Error: 0.6003157244127796\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics  \n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))  \n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))  \n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result:\n",
    "\n",
    "Wheat Seed Logistic regression:<br>\n",
    "- Normal\n",
    "0.9285714285714286<br>\n",
    "- PCA\n",
    "0.9047619047619048<br>\n",
    "- KPCA\n",
    "0.6904761904761905<br>\n",
    "\n",
    "\n",
    "Wine Data Linear regression:<br>\n",
    "- Normal\n",
    "Mean Absolute Error: 15.893100141029436<br>\n",
    "Mean Squared Error: 560.1825876096477<br>\n",
    "Root Mean Squared Error: 23.668176685364838 <br>\n",
    "\n",
    "- PCA    \n",
    "Mean Absolute Error: 0.4408379007098189<br>\n",
    "Mean Squared Error: 0.36037896897724037<br>\n",
    "Root Mean Squared Error: 0.6003157244127796<br>\n",
    "- KPCA\n",
    "Mean Absolute Error: 2584015151647.59<br>\n",
    "Mean Squared Error: 1.4246020099333066e+25<br>\n",
    "Root Mean Squared Error: 3774390030101.959<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
